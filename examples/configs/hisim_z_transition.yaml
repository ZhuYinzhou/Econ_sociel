runner: "episode_runner"
mac: "basic_mac"
learner: "q_learner"

# Offline z(t)->z(t+1) transition supervision training for secondary-user population belief.
# This trains BeliefEncoder.population_update_head in a way that directly improves hisim_social_env population_z dynamics.
t_max: 50000
test_interval: 5000
test_nepisode: 16

n_agents: 3
belief_dim: 128
population_belief_dim: 1
batch_size_run: 1

# 顶层 n_actions 统一为 5（与社交仿真一致），避免跨阶段 load_models 时 agent 输出层维度不一致。
# 注意：该离线环境实际可用动作数量仍由 env_args.n_actions=1 控制（这里动作仅占位，不参与 reward）。
n_actions: 5
env_action_source: "discrete_action_boxed"

# Disable online LLM calls
enable_llm_rollout: false
together_api_key: ""
coordinator_model: "gpt-4.1"
executor_model: "gpt-4.1"
llm_model_name: "gpt2"

# ===== 必要默认超参（train.py 不会自动继承 src/config/config.yaml）=====
lr: 0.001
belief_net_lr: 0.0001         # 降低 belief 网络学习率，避免被“无意义 TD 目标(0)”带偏
encoder_lr: 0.001
mixer_lr: 0.0001              # 同理，降低 mixer 学习率
weight_decay: 0.0
lambda_sd: 0.0                # 不用 commitment 相似损失
lambda_m: 0.0                 # 不用 local-global Q 一致性损失
stage2_weight: 0.0            # 降低/关闭 BNE 影响（该任务主要训练 z_transition head）
bne_max_iterations: 1
bne_convergence_threshold: 0.001

arch:
  entity_dim: 256
  attention_heads: 4
  transformer_blocks: 2
  key_dim: 64
  mlp_hidden_size: 256
  feedforward_size: 1024
  dropout_rate: 0.1
  layer_norm_epsilon: 0.00001

prompt_attention_heads: 2
commitment_embedding_dim: 1024

# === 关键：开启 z_transition loss ===
z_transition_loss_weight: 1.0
z_transition_loss_type: "mse"

env: "huggingface_dataset_env"
env_args:
  hf_dataset_path: "/home/zhuyinzhou/MAS/ECON/data/hisim_belief_dataset_metoo_e1_z_transition"
  dataset_split: "train"
  question_field_name: "question"
  answer_field_name: "answer"
  max_question_length: 1024
  max_answer_length: 32
  dataset_streaming: false
  use_random_sampling: true
  use_dataset_episode: false
  # don't filter; all samples in this dataset are population transition ones
  filter_is_core_user: null
  n_actions: 1
  emit_belief_fields: true
  population_belief_dim: 1

# reward: 全 0（不依赖 correctness），避免无关的 TS/AL/CC 信号干扰
reward:
  al_weight: 0.0
  ts_weight: 0.0
  cc_weight: 0.0

train:
  buffer_size: 32
  batch_size: 16
  update_interval: 10
  optimizer: "adam"
  learning_rate: 0.001
  coordinator_learning_rate: 0.0005
  gamma: 0.99

system:
  use_cuda: true
  device_num: 0
  seed: 42
  debug: false

logging:
  use_tensorboard: true
  log_interval: 20
  save_model: true
  save_model_interval: 5000
  checkpoint_path: "./models"
  log_path: "./logs"
  experiment_name: "hisim-z-transition"


